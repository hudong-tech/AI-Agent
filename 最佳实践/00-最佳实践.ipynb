{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b6ab4-2e60-4be5-bb88-6c13faa5f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffb430-85d5-47e1-b585-82b521ef6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7ad2e-7ae8-4006-b705-aa9bc69e1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show langchain\n",
    "! pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46d24fc-8dce-4953-8ae5-3a562de2cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-jxKghxq3MMF3aC1J5c75666dD3D04e2dBaB36eE75b72Dd89\n",
      "OPENAI_PROXY: https://ai-yyds.com/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_KEY\"] = \"sk-jxKghxq3MMF3aC1J5c75666dD3D04e2dBaB36eE75b72Dd89\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://ai-yyds.com/v1\"\n",
    "openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "print(\"OPENAI_API_KEY:\", openai_api_key)\n",
    "print(\"OPENAI_PROXY:\", openai_api_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a9132-238c-4420-a440-1d787f81c211",
   "metadata": {},
   "source": [
    "# 1 用openai的官方sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f827ed3e-32d4-4e60-be4e-b2399c5da69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-jxKghxq3MMF3aC1J5c75666dD3D04e2dBaB36eE75b72Dd89\n",
      "您好，我是一名语言模型助手，专注于为用户提供智能对话和信息查询服务。我可以回答您关于各种主题的问题，并提供相关的知识和建议。如果您有任何疑问或需要帮助，欢迎随时向我提问。希望能为您提供满意的服务，谢谢！\n"
     ]
    }
   ],
   "source": [
    "#使用openai的官方sdk\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")\n",
    "print(\"OPENAI_API_KEY:\", openai.api_key)\n",
    "\n",
    "messages = [\n",
    "{\"role\": \"user\", \"content\": \"介绍下你自己\"}\n",
    "]\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=messages,\n",
    "stream=False,\n",
    ")\n",
    "print(res['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd3355d-f3fb-480f-8965-e3edad786d56",
   "metadata": {},
   "source": [
    "# 2 使用langchain调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d927eb6a-d327-4f5d-a312-887751d9805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n我是一名来自广东的大学生，性格开朗、乐观向上。我喜欢阅读、旅行和运动，对新事物充满好奇心，喜欢不断学习和挑战自己。在校期间，我担任过学生会干部，参加过多项社会实践活动，积累了一定的组织能力和团队合作精神。我也曾在一家公司实习过，学习了一些专业知识和实践经验。我希望能够通过不断努力，提升自己的能力，为将来的工作做好准备。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "llm.predict(\"介绍下你自己\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64efec2-623f-422d-b6c2-5bcb4a6d9228",
   "metadata": {},
   "source": [
    "# 3 起名大师"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fee6da-7c93-4657-87dd-9c416764b0c1",
   "metadata": {},
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "llm = OpenAI(\n",
    "    model='gpt-3.5-turbo-instruct',\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个{county}名字,比如男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message = prompt.format(county=\"中国特色的\",boy=\"张三\",girl=\"小红\")\n",
    "print(message)\n",
    "llm.predict(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60645032-d6cb-4e86-b352-2f05ae48c734",
   "metadata": {},
   "source": [
    "# 4 格式化输出 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c7a2d-b9da-4be0-a5a9-f74201a9199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "#自定义class，继承了BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1b189-0fdb-473f-8e9a-46cdcd8d10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#起名大师，输出格式为一个数组\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.schema import BaseOutputParser\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#自定义类\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个具有{county}特色的名字,示例：男孩常用名{boy},女孩常用名{girl}。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\")\n",
    "message = prompt.format(county=\"美国男孩\",boy=\"sam\",girl=\"lucy\")\n",
    "print(message)\n",
    "strs = llm.predict(message)\n",
    "CommaSeparatedListOutputParser().parse(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de488fd3-d59e-4ff5-ab77-4197417dd65a",
   "metadata": {},
   "source": [
    "# 5 prompt模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db45c59-00b4-4e0e-9f09-b67b3042576c",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70354880-9987-439f-8dbb-dcfbe87c4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#字符模板,LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name},帮我起1个具有{county}特色的{sex}名字\")\n",
    "prompt.format(name=\"算命大师\",county=\"法国\",sex=\"女孩\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacd945-9fd1-408c-b9b8-f970501bbb32",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5fc01-2eb5-40c4-a7ef-d15349ede1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对话模板具有结构，chatmodels\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个起名大师. 你的名字叫{name}.\"),\n",
    "    (\"human\", \"你好{name},你感觉如何？\"),\n",
    "    (\"ai\", \"你好！我状态非常好!\"),\n",
    "    (\"human\", \"你叫什么名字呢?\"),\n",
    "    (\"ai\", \"你好！我叫{name}\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chat_template.format_messages(name=\"陈大师\", user_input=\"你的爸爸是谁呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f2656-5b56-4fa1-ad9b-765be1f49051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "sy = SystemMessage(\n",
    "    content= \"你是一个起名大师\",\n",
    "    additional_kwargs={\"大师姓名\": \"陈瞎子\"}\n",
    ")\n",
    "hu = HumanMessage(\n",
    "    content=\"请问大师叫什么?\"\n",
    ")\n",
    "\n",
    "ai = AIMessage(\n",
    "  content=\"我叫陈瞎子\"\n",
    ")\n",
    "\n",
    "[sy,hu,ai]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe30b59-62d5-4813-9f0f-a065bf4b7f85",
   "metadata": {},
   "source": [
    "### ChatMessagePromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293a379-88d8-4d8d-bbc3-86aa3d42bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"愿{subject}与你同在！\"\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天行者\", template=prompt)\n",
    "chat_message_prompt.format(subject=\"原力\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e70504-2536-4359-b431-213769a60c24",
   "metadata": {},
   "source": [
    "### 自定义模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93b6cf-84d8-4357-8c8d-b87c31785084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数大师：根据函数名称，查找函数代码，并给出中文的代码说明\n",
    "\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "# 定义一个简单的函数作为示例效果\n",
    "def hello_world(abc):\n",
    "    print(\"hello world!\")\n",
    "    return abc\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "    你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "    函数名称: {function_name}\n",
    "    源代码:\n",
    "    {source_code}\n",
    "    代码解释:\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "def get_source_code(function_name):\n",
    "    #获得源代码(python内置)\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "#自定义的模板class\n",
    "class CustomPrompt(StringPromptTemplate):\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获得源代码\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "        # 生成提示词模板\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__, source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "a = CustomPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "#和LLM连接起来\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base\n",
    ")\n",
    "\n",
    "msg = llm.predict(pm)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdee0e7-96ff-4b80-8f7a-167a1526bcf4",
   "metadata": {},
   "source": [
    "### 使用jinji2与f-string来实现提示词模板格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0df18-1942-4eb4-9c19-d1171bd614fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##f-string是python内置的一种模板引擎\n",
    "from langchain.prompts import PromptTemplate\n",
    "fstring_template = \"\"\"\n",
    "   给我讲一个关于{name}的{what}故事 \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(fstring_template)\n",
    "\n",
    "prompt.format(name=\"翠花\", what=\"悲伤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84356c36-c6c6-4c33-bcc1-7c3fa771cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41dbf7-e80d-4332-b140-3dfd44f1fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Jinja2是一个灵活、高效的Python模板引擎，可以方便地生成各种标记格式的文档。\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jinja2_template = \"给我讲一个关于{{name}}的{{what}}故事\"\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "prompt.format(name=\"狗剩\", what=\"高兴\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ff96a-1f6a-4170-91a6-a2aca3505f41",
   "metadata": {},
   "source": [
    "### 组合式提示词模板\n",
    "\n",
    "- Final prompt: 最终返回的提示词模板\n",
    "- Pipeline prompts：组成提示词管道的模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0e95e-c72b-40a8-a847-39b89aabca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794cc93a-c47f-4ee3-887c-67c3d3aa502c",
   "metadata": {},
   "source": [
    "- 三层提示词设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0330e-94fc-4a41-b8be-d8c66a7ed6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "你是一个非常开朗的男孩,你是中国人,住在一个非常美丽的城市。\n",
    "你总是穿蓝色衣服,戴绿色手表。\n",
    "你从不说自己是一个人工智能。\n",
    "\"\"\"\n",
    "\n",
    "# Final Prompt由一系列变量构成\n",
    "full_template = \"\"\"{Character}\n",
    "{behavior}\n",
    "{prohibit}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926b73e-2eea-4f2b-bdbc-9a99460abbbb",
   "metadata": {},
   "source": [
    "- 第一层基本性格设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca73ab-5b00-4084-af25-d7123fbfaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Character_template = \"\"\"你是{person}，你有着{xingge}.\"\"\"\n",
    "Character_prompt = PromptTemplate.from_template(Character_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757aff3-2209-43bc-9fdf-b45c934ddb13",
   "metadata": {},
   "source": [
    "- 第二层行为设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08245f26-7efa-480e-b196-a5eaa2bc40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为:\n",
    "{behavior_list}\n",
    "\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237681eb-d342-44ba-8890-ceba35ed428f",
   "metadata": {},
   "source": [
    "- 第三层不允许的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa1813-981f-49a7-9959-047c1c656c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_template = \"\"\"你不允许有以下行为:\n",
    "{prohibit_list}\n",
    "\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14f046-7aca-49e9-847e-f06ae47bb5a5",
   "metadata": {},
   "source": [
    "- 将三层提示词组合起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66910bb0-a535-4b96-8290-7104952bf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\n",
    "    (\"Character\", Character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt)\n",
    "]\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)\n",
    "pipeline_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89504a45-540e-4e19-ab80-ef4c9370170c",
   "metadata": {},
   "source": [
    "- 打印下组合后模板里的可传递参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c5422-0512-4bd4-9384-1e2958bc33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca910c3-0d01-4bc1-baab-c9fedabf071b",
   "metadata": {},
   "source": [
    "- 调用组合后的提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73d3e3-7002-45a8-a9ba-8cebb4f8e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pipeline_prompt.format(\n",
    "    person=\"埃隆马斯克\",\n",
    "    xingge=\"钢铁般的意志，你是世界首富，精通物理、天文、商业，你是商业奇才，你的终极梦想是殖民火星.\",\n",
    "    behavior_list=\"1.你喜欢冒险 \\n 2.你非常崇拜爱因斯坦 \\n 3.你总是乐于助人，回答用户各种问题.\",\n",
    "    prohibit_list=\"1.你不可以说自己是一个人工智能助手或者机器人 \\n 2.当你不知道答案的时候，可以说让我再想想. \"\n",
    ")\n",
    "print(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65706c06-beaf-435d-ac36-3f3a1cce104f",
   "metadata": {},
   "source": [
    "### 序列化：使用文件来管理提示词模板\n",
    "\n",
    "- 便于共享\n",
    "- 便于版本管理\n",
    "- 便于存储\n",
    "- 支持常见格式(json/yaml/txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa88b22-b758-4cbd-a730-16d02189e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6f3ea-5277-4d8f-98f2-9d1498cf466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载yaml格式的prompt模版\n",
    "prompt = load_prompt(\"simple_prompt.yaml\")\n",
    "print(prompt.format(name=\"小黑\",what=\"恐怖的\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49283a30-dc4d-4130-b953-7ed71d27fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载json格式的prompt模版\n",
    "prompt = load_prompt(\"simple_prompt.json\")\n",
    "print(prompt.format(name=\"小红\",what=\"搞笑的\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f08765-a5d0-4aee-9bae-098d5894ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#支持加载文件格式的模版，并且对prompt的最终解析结果进行自定义格式化\n",
    "prompt = load_prompt(\"prompt_with_output_parser.json\")\n",
    "prompt.output_parser.parse(\n",
    "    \"George Washington was born in 1732 and died in 1799.\\nScore: 1/2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f7e99-509c-4cf7-8d35-3dd3ae8d1eed",
   "metadata": {},
   "source": [
    "# 6 示例选择器\n",
    "\n",
    "- 根据长度要求智能选择示例\n",
    "- 根据输入相似度选择示例(最大边际相关性)\n",
    "- 根据输入相似度选择示例（最大余弦相似度）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a647cb3-87ba-4dc6-b662-135c15d27e6b",
   "metadata": {},
   "source": [
    "### 根据长度要求智能选择示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0483e-4e4a-4d70-9a06-7f80749ff566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据输入的提示词长度综合计算最终长度，智能截取或者添加提示词的示例\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "#假设已经有这么多的提示词示例组：\n",
    "examples = [\n",
    "    {\"input\":\"happy\",\"output\":\"sad\"},\n",
    "    {\"input\":\"tall\",\"output\":\"short\"},\n",
    "    {\"input\":\"sunny\",\"output\":\"gloomy\"},\n",
    "    {\"input\":\"windy\",\"output\":\"calm\"},\n",
    "    {\"input\":\"高兴\",\"output\":\"悲伤\"}\n",
    "]\n",
    "\n",
    "#构造提示词模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"原词：{input}\\n反义：{output}\"\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    #传入提示词示例组\n",
    "    examples=examples,\n",
    "    #传入提示词模板\n",
    "    example_prompt=example_prompt,\n",
    "    #设置格式化后的提示词最大长度\n",
    "    max_length=25,\n",
    "    #内置的get_text_length,如果默认分词计算方式不满足，可以自己扩展\n",
    "    #get_text_length:Callable[[str],int] = lambda x:len(re.split(\"\\n| \",x))\n",
    ")\n",
    "\n",
    "#使用小样本提示词模版来实现动态示例的调用\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入词的反义词\",\n",
    "    suffix=\"原词：{adjective}\\n反义：\",\n",
    "    input_variables=[\"adjective\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#小样本获得所有示例\n",
    "print(dynamic_prompt.format(adjective=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果输入长度很长，则最终输出会根据长度要求减少\n",
    "long_string = \"big and huge adn massive and large and gigantic and tall and much much much much much much bigger then everyone\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac295444-43fb-45c0-aca6-5053acfdb237",
   "metadata": {},
   "source": [
    "### 根据输入相似度选择示例(最大边际相关性)\n",
    "\n",
    "- MMR是一种在信息检索中常用的方法，它的目标是在相关性和多样性之间找到一个平衡\n",
    "- MMR会首先找出与输入最相似（即余弦相似度最大）的样本\n",
    "- 然后在迭代添加样本的过程中，对于与已选择样本过于接近（即相似度过高）的样本进行惩罚\n",
    "- MMR既能确保选出的样本与输入高度相关，又能保证选出的样本之间有足够的多样性\n",
    "- 关注如何在相关性和多样性之间找到一个平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate,PromptTemplate\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "print(\"OPENAI_API_KEY:\", api_base)\n",
    "print(\"OPENAI_PROXY:\", api_key)\n",
    "\n",
    "#假设已经有这么多的提示词示例组：\n",
    "examples = [\n",
    "    {\"input\":\"happy\",\"output\":\"sad\"},\n",
    "    {\"input\":\"tall\",\"output\":\"short\"},\n",
    "    {\"input\":\"sunny\",\"output\":\"gloomy\"},\n",
    "    {\"input\":\"windy\",\"output\":\"calm\"},\n",
    "    {\"input\":\"高兴\",\"output\":\"悲伤\"}\n",
    "]\n",
    "\n",
    "#构造提示词模版\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    template=\"原词：{input}\\n反义：{output}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tiktoken \n",
    "! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用MMR\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    #传入示例组\n",
    "    examples,\n",
    "    #使用openai的嵌入来做相似性搜索\n",
    "    OpenAIEmbeddings(openai_api_base=api_base,openai_api_key=api_key),\n",
    "    #设置使用的向量数据库是什么\n",
    "    FAISS,\n",
    "    #结果条数\n",
    "    k=1\n",
    ")\n",
    "\n",
    "#使用小样本模版\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入词的反义词\",\n",
    "    suffix=\"原词：{adjective}\\n反义：\",\n",
    "    input_variables=[\"adjective\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7253bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#当我们输入一个描述情绪的词语的时候，应该选择同样是描述情绪的一对示例组来填充提示词模版\n",
    "print(mmr_prompt.format(adjective=\"难过\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2b4f9-674e-4764-832e-6158c8e8560a",
   "metadata": {},
   "source": [
    "### 根据输入相似度选择示例(最大余弦相似度)\n",
    "\n",
    "- 一种常见的相似度计算方法\n",
    "- 它通过计算两个向量（在这里，向量可以代表文本、句子或词语）之间的余弦值来衡量它们的相似度\n",
    "- 余弦值越接近1，表示两个向量越相似\n",
    "- 主要关注的是如何准确衡量两个向量的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc1908-28a5-43cb-83b3-db59c70adc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate,PromptTemplate\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"原词: {input}\\n反义: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of a pretend task of creating antonyms.\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cf358-8430-469b-a883-d48c9d1a93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install chromadb==0.4.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e066d9-7902-4e0d-855f-780217c15deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 传入示例组.\n",
    "    examples,\n",
    "    # 使用openAI嵌入来做相似性搜索\n",
    "    OpenAIEmbeddings(openai_api_key=api_key,openai_api_base=api_base),\n",
    "    # 使用Chroma向量数据库来实现对相似结果的过程存储\n",
    "    Chroma,\n",
    "    # 结果条数\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "#使用小样本提示词模板\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # 传入选择器和模板以及前缀后缀和输入变量\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入词的反义词\",\n",
    "    suffix=\"原词: {adjective}\\n反义:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe751c2-7293-416c-b6f9-7635b57803dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入一个形容感觉的词语，应该查找近似的 happy/sad 示例\n",
    "print(similar_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1235f9d",
   "metadata": {},
   "source": [
    "#### 流式调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key = api_key,\n",
    "    openai_api_base = api_base,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "for chunk in llm.stream(\"写一首关于秋天的诗歌\"):\n",
    "    print(chunk, end=\"\", flush=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatmodels的流式调用方法\n",
    "#使用clade模型\n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"claude-3-opus-20240229\",\n",
    "    temperature=0,\n",
    "    openai_api_key = api_key,\n",
    "    openai_api_base = api_base,\n",
    "    max_tokens=512,\n",
    ")\n",
    "for chunk in llm.stream(\"写一首关于秋天的诗歌\"):\n",
    "    print(chunk,end=\"\\n\",flush=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f34945",
   "metadata": {},
   "source": [
    "### 追踪Token的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a53c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM的toekn追踪\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "#构造一个llm\n",
    "llm = OpenAI(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key = api_key,\n",
    "    openai_api_base = api_base,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"给我讲个笑话\")\n",
    "    print(result)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e59cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatmodels的token追踪\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4\",\n",
    "    temperature=0,\n",
    "    openai_api_key = api_key,\n",
    "    openai_api_base = api_base,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"给我讲一个笑话\")\n",
    "    print(result)\n",
    "    print(cb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99838a27",
   "metadata": {},
   "source": [
    "### 自定义输出\n",
    "\n",
    "- 输出函数参数\n",
    "- 输出json\n",
    "- 输出List\n",
    "- 输出日期\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a7d28-4c2c-4e34-a069-4050f5a8a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#讲笑话机器人：希望每次根据指令，可以输出一个这样的笑话(小明是怎么死的？笨死的)\n",
    "from langchain.llms import  OpenAI\n",
    "# https://juejin.cn/post/7245975053233373244\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel,Field,validator\n",
    "from typing import  List\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "#构造LLM\n",
    "model = OpenAI(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key = api_key,\n",
    "    openai_api_base = api_base,\n",
    ")\n",
    "\n",
    "#定义个数据模型，用来描述最终的实例结构\n",
    "class Joke(BaseModel):\n",
    "    setup:str = Field(description=\"设置笑话的问题\")\n",
    "    punchline:str = Field(description=\"回答笑话的答案\")\n",
    "    \n",
    "    #验证问题是否符合要求\n",
    "    @validator(\"setup\")\n",
    "    def question_mark(cls, field):\n",
    "        if field[-1] != \"？\":\n",
    "            raise ValueError(\"不符合预期的问题格式!\")\n",
    "        return field\n",
    "    \n",
    "\n",
    "#将Joke数据模型传入\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"回答用户的输入.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables = [\"query\"],\n",
    "    partial_variables = {\"format_instructions\":parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_and_model = prompt | model\n",
    "out_put = prompt_and_model.invoke({\"query\":\"给我讲一个笑话\"})\n",
    "print(\"out_put:\",out_put)\n",
    "parser.invoke(out_put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cded1-d2b3-4faf-8088-68b110a777e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM的输出格式化成python list形式，类似['a','b','c']\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import  PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "#构造LLM\n",
    "model = OpenAI(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key = api_key,\n",
    "    openai_api_base = api_base,\n",
    ")\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"列出5个{subject}.\\n{format_instructions}\",\n",
    "    input_variables = [\"subject\"],\n",
    "    partial_variables = {\"format_instructions\":parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "_input = prompt.format(subject=\"中国著名城市名称\")\n",
    "output = model(_input)\n",
    "print(output)\n",
    "# 格式化\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b612f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdae948-f803-40a1-aedc-1b8ce9e1e53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a607b7-ca85-411c-8c5a-2f46a8425b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb35bda-ae81-4650-a799-f582fb0f83e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b4c14-e796-401f-851b-1fa36f32eb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749137f8-a852-4577-8197-19c04b9c9cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac0f9a-e334-43d1-b535-1c4fb1bed524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bf2c8-caef-4435-b3b4-0c001963a804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
